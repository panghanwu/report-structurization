{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clinical Report Structurization\n",
    "Extract structural information from clinical reports based on specific questions.\n",
    "\n",
    "## Process\n",
    "1. Prepare inputs, including a system prompt (instructions) and a user prompt (report and questions).\n",
    "2. Send the prompts to the GPT through the OpenAI API and receive the response in JSON string.\n",
    "3. Validate the response using `json.loads` and Pydantic.\n",
    "\n",
    "## Concept JSON Schema\n",
    "```python\n",
    "[\n",
    "    {\n",
    "        \"qid\": int,  # index of the question\n",
    "        \"basis\": str,  # fact in the report according to\n",
    "        \"answer\": {type}  # {instruction for answering}\n",
    "    },\n",
    "    {\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```\n",
    "\n",
    "\n",
    "## Resources\n",
    "-  OpenAI API Docs: https://platform.openai.com/docs/guides/text-generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "\n",
    "PATH_TO_ACCESS_KEY: str = 'openai-key'\n",
    "\n",
    "with open(PATH_TO_ACCESS_KEY) as f:\n",
    "    access_key = f.read()\n",
    "    \n",
    "\n",
    "client = OpenAI(api_key=access_key)\n",
    "\n",
    "def chat(client: OpenAI, dialog: list[dict[str, str]]) -> str:\n",
    "    result = client.chat.completions.create(\n",
    "        model='gpt-4o', \n",
    "        messages=dialog,\n",
    "        top_p=0.0  # no randomness\n",
    "    )\n",
    "    return result.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (1) Prepare\n",
    "\n",
    "system_prompt = \"\"\"\n",
    "You are an assistant designed to convert a clinical report into JSON-formatted outputs based on specific questions, following the provided schema and the listed instructions.\n",
    "```python\n",
    "[\n",
    "    {\n",
    "        \"qid\": int,  # index of the question,\n",
    "        \"basis\": str,  # fact in the report according to,\n",
    "        \"answer\": int  # the index of the chosen option\n",
    "    },\n",
    "    {\n",
    "        ...\n",
    "    },\n",
    "    ...\n",
    "]\n",
    "```\n",
    "- Do not use the markdown syntax to wrap the JSON output.\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Report:\n",
    "{{report}}\n",
    "\n",
    "Question:\n",
    "{{questions}}\n",
    "\"\"\"\n",
    "\n",
    "report = r\"\"\"\n",
    " 1. The stress imaging:\n",
    "   The stress imaging following dipyridamole I.V. infusion and   \n",
    "   the post-dipyridamole SPECT images reveal:\n",
    "    \n",
    "   Moderate hypoperfusion over the apex, septal, inferior and  \n",
    "   lateral walls of LV. \n",
    "    \n",
    "   (extent: 20% LAD, 30% of RCA & 20% of LCx territories) \n",
    " 2. The resting imaging: \n",
    "    \n",
    "   As compared to the stress images, this 4-hour redistribution \n",
    "   images reveal partial reperfusion to the aforementioned areas. \n",
    "    \n",
    " Conclusion : \n",
    "     \n",
    "    1. The current study demonstrates partially reversible,\n",
    "       moderate hypoperfusion over the apex, septal, inferior\n",
    "       and lateral walls of LV, suggests moderate CAD involving 3VD \n",
    "       territories. Please evaluate clinically. \n",
    "     \n",
    "    2. We would like to follow up closely. \n",
    "\n",
    "\"\"\"\n",
    "\n",
    "questions = r\"\"\"\n",
    "Please answer the following questions based on the TL-201 report information.\n",
    "\n",
    "Options for the following questions: \n",
    "1. No\n",
    "2. Minimal\n",
    "3. Mild\n",
    "4. Moderate\n",
    "5. Severe\n",
    "6. Extensive\n",
    "\n",
    "Q1. Perfusion defect severity in Basal Anterior (apex)?\n",
    "Q2. Perfusion defect severity in Basal Anteroseptal\n",
    "Q3. Perfusion defect severity in Basal Inferoseptal\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = user_prompt.replace('{{report}}', report)\n",
    "user_prompt = user_prompt.replace('{{questions}}', questions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    {\n",
      "        \"qid\": 1,\n",
      "        \"basis\": \"Moderate hypoperfusion over the apex, septal, inferior and lateral walls of LV.\",\n",
      "        \"answer\": 4\n",
      "    },\n",
      "    {\n",
      "        \"qid\": 2,\n",
      "        \"basis\": \"Moderate hypoperfusion over the apex, septal, inferior and lateral walls of LV.\",\n",
      "        \"answer\": 4\n",
      "    },\n",
      "    {\n",
      "        \"qid\": 3,\n",
      "        \"basis\": \"Moderate hypoperfusion over the apex, septal, inferior and lateral walls of LV.\",\n",
      "        \"answer\": 4\n",
      "    }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# (2) Send and receive\n",
    "dialog = [\n",
    "    {'role': 'system', 'content': system_prompt},\n",
    "    {'role': 'user', 'content': user_prompt}\n",
    "]\n",
    "output = chat(client, dialog)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Validate the json format\n",
    "# dialog = [\n",
    "#     {'role': 'system', 'content': system_prompt},\n",
    "#     {'role': 'user', 'content': user_prompt}\n",
    "# ]\n",
    "\n",
    "# while True:\n",
    "#     output = chat(client, dialog)\n",
    "    \n",
    "#     try:\n",
    "#         structured_answers = json.loads(output)\n",
    "#         break\n",
    "#     except json.JSONDecodeError as e:\n",
    "#         dialog.append({'role': 'assistant', 'content': output})\n",
    "#         dialog.append({'role': 'system', 'content': f'JSONDecodeError: {e}.'})\n",
    "#         print(f'JSONDecodeError {e}: request re-generating.')\n",
    "\n",
    "# structured_answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Answer(qid=1, basis='Moderate hypoperfusion over the apex, septal, inferior and lateral walls of LV.', answer=4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Validate data types of the response\n",
    "from pydantic import BaseModel\n",
    "\n",
    "structured_answers = json.loads(output)\n",
    "\n",
    "class Answer(BaseModel):\n",
    "    qid: int\n",
    "    basis: str\n",
    "    answer: int\n",
    "\n",
    "answers = [Answer(**a) for a in structured_answers]\n",
    "\n",
    "answers[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python311",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
